{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# How do I work with data in the cloud?\n",
    "***\n",
    "This Notebook will answer some \"first-time\" questions about working with cloud data. We'll then cover a basic example of cloud access syntax that you can copy for your own use.\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "- Describe the basic workflow for accessing data in the cloud\n",
    "- Apply this cloud workflow to your own data queries\n",
    "\n",
    "## Notebook TOC\n",
    "- [Introduction](Introduction)\n",
    "- [Imports and setup](Imports-and-Setup)\n",
    "- [A Quick Query](A-Quick-Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "### What is \"the cloud\"? \n",
    "\n",
    "In this case, \"the cloud\" is the AWS East Datacenters in northern Virginia. By storing a cloud copy of MAST data here, we're able to offer our data in a new, highly accessible, highly available format. Cloud hosted data also permits users to interact with our data in new ways, as we'll see in the example below.\n",
    "\n",
    "### What datasets are available?\n",
    "\n",
    "The [MAST Archive](https://archive.stsci.edu/) offers a cloud copy of several mission datasets, including data from TESS, HST, GALEX, and more. They are generally cataloged in full on the [MAST Public Datasets](https://registry.opendata.aws/collab/stsci/) page, with a more condensed listing available on the [Public AWS Data](https://outerspace.stsci.edu/display/MASTDOCS/Public+AWS+Data) page.\n",
    "\n",
    "### How can I access cloud-hosted data?\n",
    "\n",
    "There are two approaches to accessing cloud-hosted data:\n",
    "1. While on TIKE, loading files directly into memory (recommended)\n",
    "2. A traditional download to your local machine from the cloud-hosted copy of MAST\n",
    "\n",
    "Whenever possible, it's best to use the first method. The vast majority of users, with small tweaks to existing code, should be able to access data this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imports and Setup\n",
    "\n",
    "We'll use the standard tools to open and plot a fits file:\n",
    "- `astropy.io fits` to read in the fits file\n",
    "- `matplotlib` to create the plot\n",
    "- `numpy` to automatically set brightness limits in the plot\n",
    "\n",
    "To access the cloud data, we need\n",
    "- `astroquery.mast` to search for and select data\n",
    "- `s3fs` to access cloud files as though they were local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import s3fs\n",
    "\n",
    "from astropy.io import fits\n",
    "from astroquery.mast import Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important step in this process is to enable cloud data access. Once we do\n",
    "- Get cloud URIs\n",
    "- Download from the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.enable_cloud_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Query\n",
    "\n",
    "Now we can begin our query. This is not a particularly interesting query, but makes for a nice, quick example. We'll look for a particular HST Observation, then keep only the minimum recommended science files from that observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# You likely wouldn't search on obs_id, but it makes this example reproducable\n",
    "obs = Observations.query_criteria(obs_id=\"ibxl50020\")\n",
    "\n",
    "# Get the products, then filter to keep science and MRP (minimum recommended products)\n",
    "prod = Observations.get_product_list(obs)\n",
    "filtered = Observations.filter_products(prod, mrp_only=True, productType='SCIENCE')\n",
    "\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD: \"something about the results\"\n",
    "\n",
    "Now let's get a cloud URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_uri = Observations.get_cloud_uris(filtered)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files directly into memory\n",
    "Set up the filesystem so Python can read it. Note: must be anonymous to access data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using \"with\" syntax to avoid timeouts on s3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(c_uri, 'rb') as f:\n",
    "    with fits.open(f, 'readonly') as ff:\n",
    "        ff.info()\n",
    "        sci = ff[1].data\n",
    "        plt.imshow(sci, cmap='gray', norm='log', vmin=np.nanpercentile(sci, 1), vmax=np.nanpercentile(sci,99))\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow! we plotted data without downloading! we read directly from the AWS filesystem, super cool\n",
    "\n",
    "## Also you could just download directly\n",
    "\n",
    "## Other methods and notes/caveats\n",
    "\n",
    "### AWS command-line tool\n",
    "### Integrated methods\n",
    "e.g. lightcurve will do a download, which clogs up your storage on TIKE\n",
    "status of astrocut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this Notebook\n",
    "\n",
    "open a PR or issue or send an email if you must\n",
    "\n",
    "\n",
    "**Author:** Thomas Dutkiewicz <br>\n",
    "**Keyword(s):** TIKE, AWS, Cloud <br>\n",
    "**Last Updated:** Dec 2023 <br>\n",
    "***\n",
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
