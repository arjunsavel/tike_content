{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to work with data in the cloud?\n",
    "\n",
    "The [MAST data archive](https://archive.stsci.edu/) provides a copy of several large NASA data sets via Amazon Web Services (AWS) as part of the [MAST AWS Public Datasets](https://registry.opendata.aws/collab/stsci/) program.\n",
    "\n",
    "This service is of interest to TIKE users, because the TIKE platform is hosted by AWS and therefore provides fast access to these data sets. The data are free to access and download: they do not require you to have an AWS account or use AWS credentials.\n",
    "\n",
    "Below we demonstrate a few ways to access the data.\n",
    "\n",
    "\n",
    "## Which data sets are available in the cloud?\n",
    "\n",
    "At the time of writing, selected data sets from Hubble, Kepler, K2, and TESS are available via the AWS S3 cloud file storage service.  You can read more details about this service via the following MAST blog posts:\n",
    "\n",
    "* [Making HST Public Data Available on AWS](https://mast-labs.stsci.io/2018/06/hst-public-data-on-aws)\n",
    "* [TESS data available on AWS](https://mast-labs.stsci.io/2018/12/tess-data-available-on-aws)\n",
    "* [Kepler Prime Mission Data Available on AWS](https://mast-labs.stsci.io/2019/10/kepler-data-available-on-aws)\n",
    "\n",
    "## How can I access the cloud-hosted data?\n",
    "\n",
    "The data can be accessed using various client libraries, including astroquery, lightkurve, aws-cli, boto3, s3fs, and others. Below we demonstrate a few basic ways to use these tools.\n",
    "\n",
    "### 1. Using the AWS command-line tool\n",
    "\n",
    "A useful tool to explore data in S3 is to use the [AWS command-line interface](https://docs.aws.amazon.com/cli/). This tool is pre-installed on the TIKE platform and can be executed from a Terminal window (<span style=\"font-variant:small-caps;\">file › new › terminal</span>) or from a Jupyter notebook (by prefixing it with the `!` character).\n",
    "\n",
    "For example, we can list the contents of the TESS data held in the public MAST AWS S3 bucket as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://stpubdata/tess/public/ --no-sign-request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in this bucket follow a specific directory structure and file name convention ([documented here](https://archive.stsci.edu/missions-and-data/tess/data-products)). For example, the TESS Sector 11 data products for Proxima Centauri (also known as TIC 388857263) are available at the following location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://stpubdata/tess/public/tid/s0011/0000/0003/8885/7263/ --no-sign-request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can copy files from this location using the `aws s3 cp` command.  For example, we can obtain the Target Pixel File (`*tp.fits`) for Proxima Centauri as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://stpubdata/tess/public/tid/s0011/0000/0003/8885/7263/tess2019112060037-s0011-0000000388857263-0143-s_tp.fits . --no-sign-request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the AWS [command line interface documentation](https://docs.aws.amazon.com/cli/latest/reference/s3/) to explore additional features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using `s3fs`\n",
    "\n",
    "The [s3fs](https://s3fs.readthedocs.io/en/latest/) package provides a Pythonic file interface to AWS S3.  This enables us to execute the commands demonstrated above from Python rather than the command line. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tool\n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "# List the directory containing Proxima Cen data\n",
    "fs.ls('s3://stpubdata/tess/public/tid/s0011/0000/0003/8885/7263/', refresh=True)\n",
    "\n",
    "# Transfer the Target Pixel File for Proxima Cen from S3\n",
    "f = fs.get('s3://stpubdata/tess/public/tid/s0011/0000/0003/8885/7263/tess2019112060037-s0011-0000000388857263-0143-s_tp.fits', 'proxima_cen_tp.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using `astroquery`\n",
    "\n",
    "The tools shown above require an understanding of the file name convention in use by each mission. An easier alternative is to use the [astroquery](https://astroquery.readthedocs.io) package, which allows file names to be queried via the MAST API.  For example, we can query and download the same Proxima Centauri data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query MAST for TESS Sector 11 observations of Proxima Cen\n",
    "from astroquery.mast import Observations\n",
    "obs = Observations.query_object(\"Proxima Cen\", radius=\"0s\")\n",
    "want = (obs['obs_collection'] == \"TESS\") & (obs['sequence_number'] == 11) & (obs['dataproduct_type'] == 'timeseries')\n",
    "\n",
    "# Pick which products we want to retrieve\n",
    "data_prod = Observations.get_product_list(obs[want])\n",
    "filt_prod = Observations.filter_products(data_prod, description=\"Target pixel files\")\n",
    "\n",
    "# Download the product from AWS S3\n",
    "Observations.enable_cloud_dataset(provider='AWS')\n",
    "manifest = Observations.download_products(filt_prod, cloud_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in the example above, the call to `enable_cloud_dataset()` is key to ensure data is downloaded from AWS rather than MAST's servers.  You can read more about this feature in the [astroquery documentation](https://astroquery.readthedocs.io/en/latest/mast/mast.html?highlight=cloud#cloud-data-access)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using `lightkurve`\n",
    "\n",
    "The [Lightkurve package](https://docs.lightkurve.org) provides search functions which use `astroquery` to search and retrieve specific TESS and Kepler data products in a more user-friendly way.  For example, we can obtain the Proxima Centauri data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: ensure files are retrieved from AWS \n",
    "from astroquery.mast import Observations\n",
    "Observations.enable_cloud_dataset(provider='AWS')\n",
    "\n",
    "import lightkurve as lk\n",
    "search = lk.search_targetpixelfile(\"Proxima Cen\", sector=11, mission=\"TESS\")\n",
    "pixelfile = search[0].download(download_dir=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the call to `enable_cloud_dataset()` is key because Lightkurve uses Astroquery behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "Additional examples are available here:\n",
    "- [Using Cloud-Hosted Data](../code/cloud_astroquery.ipynb)\n",
    "- [Reading Public Kepler Data from S3](../code/s3buckets_boto3.ipynb)\n",
    "- Creating cutouts from TESS FFI data hosted in AWS (content in progress)\n",
    "- How to read and write data to your own S3 bucket (content in progress)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
